import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import warnings
import os
from PIL import Image
import cv2
from collections import Counter

from ClassificationModel import ImprovedCNN

# –û—Ç–∫–ª—é—á–∞–µ–º warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
IMG_SIZE = (224, 224)
BATCH_SIZE = 256
NUM_EPOCHS = 50
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}")


class TreeDataset(Dataset):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Ä–∞—Å—Ç–µ–Ω–∏–π —Å –Ω–∞–¥–µ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    def __init__(self, image_paths, labels, plant_types=None, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.plant_types = plant_types
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        plant_type = self.plant_types[idx] if self.plant_types is not None else 0
        
        image = self.load_image_safe(img_path)
        
        if self.transform:
            image = self.transform(image)
        
        return image, label, plant_type
    
    def load_image_safe(self, img_path):
        try:
            image = cv2.imread(str(img_path))
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                image = Image.fromarray(image)
                return image
        except:
            pass
        
        try:
            image = Image.open(img_path).convert('RGB')
            return image
        except:
            pass
        
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {img_path}, —Å–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        return Image.new('RGB', IMG_SIZE, color='black')

def load_tree_species_data_separated(porody_folder_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ –¥–µ—Ä–µ–≤—å—è –∏ –∫—É—Å—Ç—ã"""
    porody_path = Path(porody_folder_path)
    
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {porody_path.absolute()}")
    
    if not porody_path.exists():
        print(f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {porody_path}")
        return [], [], [], [], [], []
    
    # –ò—â–µ–º CSV —Ñ–∞–π–ª
    csv_path = porody_path / "labels" / "labels.csv"
    if not csv_path.exists():
        csv_path = porody_path / "labels.csv"
        if not csv_path.exists():
            print("CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return [], [], [], [], [], []
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
        print(f"CSV –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return [], [], [], [], [], []
    
    # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    images_dir = porody_path / "images"
    if not images_dir.exists():
        print("–ü–∞–ø–∫–∞ 'images' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return [], [], [], [], [], []
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –¥–µ—Ä–µ–≤—å—è –∏ –∫—É—Å—Ç—ã
    tree_images = []
    tree_labels = []
    tree_species = []
    
    bush_images = []
    bush_labels = [] 
    bush_species = []
    
    successful = 0
    for _, row in df.iterrows():
        try:
            filename = str(row['filename']).strip()
            img_path = images_dir / filename
            
            if not img_path.exists():
                print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}")
                continue
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ä–∞—Å—Ç–µ–Ω–∏—è (0-–¥–µ—Ä–µ–≤–æ, 1-–∫—É—Å—Ç)
            if 'plant_type' in df.columns:
                plant_type = int(row['plant_type'])
            else:
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é, –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç
                species_name = str(row['species_name']).lower()
                if any(word in species_name for word in ['—Ä–æ–∑–∞', '–∫—É—Å—Ç', '–∫—É—Å—Ç–∞—Ä–Ω–∏–∫', '–º–æ–∂–∂–µ–≤–µ–ª—å–Ω–∏–∫', '—Å–∏—Ä–µ–Ω—å']):
                    plant_type = 1
                else:
                    plant_type = 0
            
            if plant_type == 0:  # –î–µ—Ä–µ–≤–æ
                tree_images.append(str(img_path))
                tree_labels.append(int(row['species_label']))
                tree_species.append(str(row['species_name']))
            else:  # –ö—É—Å—Ç
                bush_images.append(str(img_path))
                bush_labels.append(int(row['species_label']))
                bush_species.append(str(row['species_name']))
                
            successful += 1
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {successful}/{len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"–î–µ—Ä–µ–≤—å—è: {len(tree_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(tree_labels))} –≤–∏–¥–æ–≤")
    print(f"–ö—É—Å—Ç—ã: {len(bush_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(bush_labels))} –≤–∏–¥–æ–≤")
    
    return tree_images, tree_labels, tree_species, bush_images, bush_labels, bush_species

def get_enhanced_transforms():
    train_transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.2),
        transforms.RandomRotation(degrees=30),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform


def get_class_weights(labels, num_classes):
    class_counts = Counter(labels)
    print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {dict(class_counts)}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —á–∞—Å—Ç–æ—Ç–µ –∫–ª–∞—Å—Å–æ–≤
    weights = []
    for i in range(num_classes):
        if i in class_counts:
            weights.append(1.0 / class_counts[i])
        else:
            weights.append(1.0)  # –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∞ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
    weights = np.array(weights)
    weights = weights / weights.sum() * len(weights)
    weights = torch.FloatTensor(weights).to(DEVICE)
    
    print(f"–í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {weights.cpu().numpy()}")
    return weights

def check_class_balance(labels, class_names, dataset_name):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤"""
    label_counts = Counter(labels)
    
    print(f"\n–ë–ê–õ–ê–ù–° –ö–õ–ê–°–°–û–í ({dataset_name}):")
    total_samples = len(labels)
    for label, count in label_counts.items():
        class_name = class_names[label] if label < len(class_names) else f"Class {label}"
        percentage = (count / total_samples) * 100
        print(f"  {class_name}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({percentage:.1f}%)")

def train_single_model(model, train_loader, val_loader, num_epochs, num_classes, model_type="plant"):

    model = model.to(DEVICE)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    train_labels = []
    for _, labels, _ in train_loader:
        train_labels.extend(labels.cpu().numpy())
    
    class_weights = get_class_weights(train_labels, num_classes)
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)
    
    train_losses = []
    val_accuracies = []
    learning_rates = []
    
    best_accuracy = 0
    best_model_state = None
    patience = 10
    patience_counter = 0
    
    for epoch in range(num_epochs):
        try:
            # –û–±—É—á–µ–Ω–∏–µ
            model.train()
            running_loss = 0.0
            batch_count = 0
            
            for batch_idx, (images, labels, _) in enumerate(train_loader):
                try:
                    images = images.to(DEVICE)
                    labels = labels.to(DEVICE)
                    
                    optimizer.zero_grad()
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                    
                    running_loss += loss.item()
                    batch_count += 1
                    
                    if batch_idx % 10 == 0:
                        current_lr = optimizer.param_groups[0]['lr']
                        print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}, LR: {current_lr:.2e}')
                        
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_idx}: {e}")
                    continue
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            model.eval()
            correct = 0
            total = 0
            val_loss = 0.0
            
            with torch.no_grad():
                for images, labels, _ in val_loader:
                    try:
                        images = images.to(DEVICE)
                        labels = labels.to(DEVICE)
                        outputs = model(images)
                        loss = criterion(outputs, labels)
                        val_loss += loss.item()
                        
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                        continue
            
            accuracy = 100 * correct / total if total > 0 else 0
            avg_train_loss = running_loss / batch_count if batch_count > 0 else 0
            avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0
            
            current_lr = optimizer.param_groups[0]['lr']
            learning_rates.append(current_lr)
            train_losses.append(avg_train_loss)
            val_accuracies.append(accuracy)
            
            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%, LR: {current_lr:.2e}')
            

            scheduler.step(accuracy)
            
            # Early stopping –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_model_state = model.state_dict().copy()
                patience_counter = 0
                print(f"–ù–æ–≤—ã–π —Ä–µ–∫–æ—Ä–¥ —Ç–æ—á–Ω–æ—Å—Ç–∏: {accuracy:.2f}%")
            else:
                patience_counter += 1
                
            if patience_counter >= patience:
                print(f"Early stopping –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
                break
            
        except Exception as e:
            print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —ç–ø–æ—Ö–µ {epoch+1}: {e}")
            continue
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º weights –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –≤–µ—Å–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {best_accuracy:.2f}%")
    
    return model, {'train_loss': train_losses, 'val_accuracy': val_accuracies, 'learning_rates': learning_rates}


def can_use_stratified_split(labels, test_size=0.2):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"""
    label_counts = Counter(labels)
    min_samples_per_class = min(label_counts.values())
    
    # –î–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –æ–±—Ä–∞–∑—Ü–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ
    return min_samples_per_class >= 2 and all(count >= int(1/test_size) + 1 for count in label_counts.values())

def apply_data_augmentation_balance(image_paths, labels, max_samples_per_class=100):
    """–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –º–∏–Ω–æ—Ä–∏—Ç–∞—Ä–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤"""
    label_counts = Counter(labels)
    max_count = max(label_counts.values())
    
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if max_count <= min(label_counts.values()) * 2:
        return image_paths, labels
    
    print("üîÑ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é...")
    
    augmented_images = list(image_paths)
    augmented_labels = list(labels)
    
    for class_label, count in label_counts.items():
        if count < max_count:
            # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞
            class_indices = [i for i, label in enumerate(labels) if label == class_label]
            needed_samples = min(max_count - count, max_samples_per_class - count)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è)
            for i in range(needed_samples):
                original_idx = class_indices[i % len(class_indices)]
                augmented_images.append(image_paths[original_idx])
                augmented_labels.append(class_label)
    
    print(f"–ü–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {len(augmented_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    return augmented_images, augmented_labels

def prepare_and_train_model(image_paths, labels, species_names, model_type="plant"):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    if len(image_paths) == 0:
        print(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_type}")
        return None, None, []
    
    print(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(labels))} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0..C-1
    unique_labels_sorted = sorted(set(labels))
    original_to_compact = {orig: idx for idx, orig in enumerate(unique_labels_sorted)}
    labels_mapped_all = [original_to_compact[l] for l in labels]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–ª–∞—Å—Å–æ–≤
    class_names = []
    for orig_label in unique_labels_sorted:
        for path_i, lab in enumerate(labels):
            if lab == orig_label:
                class_names.append(species_names[path_i])
                break

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
    check_class_balance(labels_mapped_all, class_names, f"{model_type} (–∏—Å—Ö–æ–¥–Ω—ã–µ)")
    
    # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    balanced_paths, balanced_labels = apply_data_augmentation_balance(image_paths, labels_mapped_all)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if len(balanced_paths) <= 3:
        print("–û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö! –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        train_paths, train_labels = balanced_paths, balanced_labels
        val_paths, val_labels = balanced_paths, balanced_labels
    elif can_use_stratified_split(balanced_labels):
        print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            balanced_paths, balanced_labels, test_size=0.2, random_state=42, stratify=balanced_labels
        )
    else:
        print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞)")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            balanced_paths, balanced_labels, test_size=0.2, random_state=42, stratify=None
        )
    
    print(f"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_paths)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(val_paths)} –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö")
    check_class_balance(train_labels, class_names, f"{model_type} (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ)")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
    train_transform, val_transform = get_enhanced_transforms()
    
    train_dataset = TreeDataset(train_paths, train_labels, transform=train_transform)
    val_dataset = TreeDataset(val_paths, val_labels, transform=val_transform)
    
    batch_size = min(BATCH_SIZE, len(train_paths))
    if batch_size == 0:
        batch_size = 1
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
    
    num_classes = len(unique_labels_sorted)
    model = ImprovedCNN(num_classes)
    
    model, history = train_single_model(model, train_loader, val_loader, 
                                      NUM_EPOCHS, num_classes, model_type)

    return model, history, class_names

def train_separated_models(porody_folder_path):
    
    (tree_images, tree_labels, tree_species,
     bush_images, bush_labels, bush_species) = load_tree_species_data_separated(porody_folder_path)
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ä–µ–≤—å–µ–≤
    tree_model, tree_history, tree_class_names = None, None, []
    if len(tree_images) > 0:
        print("\n" + "="*50)
        print("–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –î–ï–†–ï–í–¨–ï–í")
        print("="*50)
        tree_model, tree_history, tree_class_names = prepare_and_train_model(
            tree_images, tree_labels, tree_species, "–¥–µ—Ä–µ–≤—å—è"
        )
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∫—É—Å—Ç–æ–≤  
    bush_model, bush_history, bush_class_names = None, None, []
    if len(bush_images) > 0:
        print("\n" + "="*50)
        print("–û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò –î–õ–Ø –ö–£–°–¢–û–í")
        print("="*50)
        bush_model, bush_history, bush_class_names = prepare_and_train_model(
            bush_images, bush_labels, bush_species, "–∫—É—Å—Ç—ã"
        )
    
    return tree_model, bush_model, tree_class_names, bush_class_names

def train_defects_model_improved(characteristiki_folder_path):

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–µ—Ñ–µ–∫—Ç–æ–≤
    image_paths, labels, defect_descriptions = load_defects_data(characteristiki_folder_path)
    
    if len(image_paths) == 0:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –¥–µ—Ñ–µ–∫—Ç–æ–≤!")
        return None, None, [], [], []
    
    print(f"–î–∞–Ω–Ω—ã–µ –¥–µ—Ñ–µ–∫—Ç–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(labels))} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –ø–æ—Ä–æ–¥–∞–º)
    model, history, class_names = prepare_and_train_model(
        image_paths, labels, defect_descriptions, "–¥–µ—Ñ–µ–∫—Ç—ã"
    )
    
    return model, history, class_names, image_paths, labels

def load_defects_data(characteristiki_folder_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫/–¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    char_path = Path(characteristiki_folder_path)
    
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–µ—Ñ–µ–∫—Ç–æ–≤ –∏–∑: {char_path.absolute()}")
    
    if not char_path.exists():
        print(f"–ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {char_path}")
        return [], [], []
    
    # –ò—â–µ–º CSV —Ñ–∞–π–ª
    csv_path = char_path / "labels" / "labels.csv"
    if not csv_path.exists():
        csv_path = char_path / "labels.csv"
        if not csv_path.exists():
            print("CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return [], [], []
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
        print(f"CSV –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return [], [], []
    
    # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    images_dir = char_path / "images"
    if not images_dir.exists():
        print("–ü–∞–ø–∫–∞ 'images' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return [], [], []
    
    images = []
    labels = []
    defect_descriptions = []
    
    successful = 0
    for _, row in df.iterrows():
        try:
            filename = str(row['filename']).strip()
            img_path = images_dir / filename
            
            if img_path.exists():
                images.append(str(img_path))
                labels.append(int(row['defect_label']))
                defect_descriptions.append(str(row['defect_description']))
                successful += 1
            else:
                print(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}")
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    
    return images, labels, defect_descriptions