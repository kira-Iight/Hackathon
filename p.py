import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision import models
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import warnings
import os
from PIL import Image
import cv2

# –û—Ç–∫–ª—é—á–∞–µ–º warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
IMG_SIZE = (224, 224)
BATCH_SIZE = 2
NUM_EPOCHS = 5
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}")

class TreeDataset(Dataset):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–µ—Ä–µ–≤—å–µ–≤ —Å –Ω–∞–¥–µ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
        image = self.load_image_safe(img_path)
        
        if self.transform:
            image = self.transform(image)
        
        return image, label
    
    def load_image_safe(self, img_path):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ fallback'–∞–º–∏"""
        try:
            # –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenCV
            image = cv2.imread(str(img_path))
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                image = Image.fromarray(image)
                return image
        except:
            pass
        
        try:
            # –°–ø–æ—Å–æ–± 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –Ω–∞–ø—Ä—è–º—É—é
            image = Image.open(img_path).convert('RGB')
            return image
        except:
            pass
        
        # –°–ø–æ—Å–æ–± 3: –°–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ fallback
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {img_path}, —Å–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        return Image.new('RGB', IMG_SIZE, color='black')

def load_tree_species_data(porody_folder_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥ –¥–µ—Ä–µ–≤—å–µ–≤"""
    porody_path = Path(porody_folder_path)
    
    print(f"üîç –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {porody_path.absolute()}")
    
    if not porody_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {porody_path}")
        return [], [], []
    
    # –ò—â–µ–º CSV —Ñ–∞–π–ª
    csv_path = porody_path / "labels" / "labels.csv"
    if not csv_path.exists():
        csv_path = porody_path / "labels.csv"
        if not csv_path.exists():
            print("‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return [], [], []
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
        print(f"‚úÖ CSV –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return [], [], []
    
    # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    images_dir = porody_path / "images"
    if not images_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ 'images' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return [], [], []
    
    images = []
    labels = []
    species_names = []
    
    successful = 0
    for _, row in df.iterrows():
        try:
            filename = str(row['filename']).strip()
            img_path = images_dir / filename
            
            if img_path.exists():
                images.append(str(img_path))
                labels.append(int(row['species_label']))
                species_names.append(str(row['species_name']))
                successful += 1
            else:
                print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {successful}/{len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(set(labels))}")
    
    return images, labels, species_names

def load_defects_data(characteristiki_folder_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫/–¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    char_path = Path(characteristiki_folder_path)
    
    print(f"üîç –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {char_path.absolute()}")
    
    if not char_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {char_path}")
        return [], [], []
    
    # –ò—â–µ–º CSV —Ñ–∞–π–ª
    csv_path = char_path / "labels" / "labels.csv"
    if not csv_path.exists():
        csv_path = char_path / "labels.csv"
        if not csv_path.exists():
            print("‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return [], [], []
    
    try:
        try:
            df = pd.read_csv(csv_path, encoding='utf-8')
        except:
            df = pd.read_csv(csv_path, encoding='utf-8', on_bad_lines='skip')
        print(f"‚úÖ CSV –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return [], [], []
    
    # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    images_dir = char_path / "images"
    if not images_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ 'images' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return [], [], []
    
    images = []
    labels = []
    defect_descriptions = []
    
    successful = 0
    for _, row in df.iterrows():
        try:
            filename = str(row['filename']).strip()
            img_path = images_dir / filename
            
            if img_path.exists():
                images.append(str(img_path))
                labels.append(int(row['defect_label']))
                defect_descriptions.append(str(row['defect_description']))
                successful += 1
            else:
                print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {successful}/{len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(set(labels))}")
    
    return images, labels, defect_descriptions

def get_transforms():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    train_transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.RandomHorizontalFlip(p=0.3),
        transforms.RandomRotation(degrees=10),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform

def create_simple_model(num_classes):
    """–°–æ–∑–¥–∞–Ω–∏–µ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ PyTorch"""
    class SimpleCNN(nn.Module):
        def __init__(self, num_classes):
            super(SimpleCNN, self).__init__()
            self.features = nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(16, 32, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(32, 64, kernel_size=3, padding=1),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool2d((1, 1))
            )
            self.classifier = nn.Sequential(
                nn.Dropout(0.3),
                nn.Linear(64, 32),
                nn.ReLU(inplace=True),
                nn.Linear(32, num_classes)
            )
        
        def forward(self, x):
            x = self.features(x)
            x = x.view(x.size(0), -1)
            x = self.classifier(x)
            return x
    
    return SimpleCNN(num_classes)

def train_model_safe(model, train_loader, val_loader, num_epochs, num_classes, model_type="–ø–æ—Ä–æ–¥—ã"):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    model = model.to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
    
    train_losses = []
    val_accuracies = []
    
    print(f"üéØ –ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò {model_type.upper()}...")
    
    for epoch in range(num_epochs):
        try:
            # –û–±—É—á–µ–Ω–∏–µ
            model.train()
            running_loss = 0.0
            batch_count = 0
            
            for batch_idx, (images, labels) in enumerate(train_loader):
                try:
                    images = images.to(DEVICE)
                    labels = labels.to(DEVICE)
                    
                    optimizer.zero_grad()
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    optimizer.step()
                    
                    running_loss += loss.item()
                    batch_count += 1
                    
                    if batch_idx % 5 == 0:
                        print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')
                        
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_idx}: {e}")
                    continue
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            model.eval()
            correct = 0
            total = 0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    try:
                        images = images.to(DEVICE)
                        labels = labels.to(DEVICE)
                        outputs = model(images)
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                        continue
            
            accuracy = 100 * correct / total if total > 0 else 0
            avg_loss = running_loss / batch_count if batch_count > 0 else 0
            
            train_losses.append(avg_loss)
            val_accuracies.append(accuracy)
            
            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —ç–ø–æ—Ö–µ {epoch+1}: {e}")
            continue
    
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    return model, {'train_loss': train_losses, 'val_accuracy': val_accuracies}

def can_use_stratified_split(labels, test_size=0.2):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"""
    from collections import Counter
    label_counts = Counter(labels)
    min_samples_per_class = min(label_counts.values())
    
    # –î–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –æ–±—Ä–∞–∑—Ü–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ
    # –∏ —Ö–æ—Ç—è –±—ã 1 –æ–±—Ä–∞–∑–µ—Ü –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    return min_samples_per_class >= 2 and all(count >= int(1/test_size) + 1 for count in label_counts.values())

def train_tree_species_model_simple(porody_folder_path):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥ –¥–µ—Ä–µ–≤—å–µ–≤"""
    
    print("üå≥ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ü–û–†–û–î –î–ï–†–ï–í–¨–ï–í")
    print("=" * 50)
    
    image_paths, labels, species_names = load_tree_species_data(porody_folder_path)
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return None, None, [], [], []
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(labels))} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0..C-1
    unique_labels_sorted = sorted(set(labels))
    original_to_compact = {orig: idx for idx, orig in enumerate(unique_labels_sorted)}
    labels_mapped_all = [original_to_compact[l] for l in labels]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–ª–∞—Å—Å–æ–≤
    class_names = []
    for orig_label in unique_labels_sorted:
        for path_i, lab in enumerate(labels):
            if lab == orig_label:
                class_names.append(species_names[path_i])
                break

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if len(image_paths) <= 3:
        print("‚ö†Ô∏è –û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö! –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        train_paths, train_labels = image_paths, labels_mapped_all
        val_paths, val_labels = image_paths, labels_mapped_all
    elif can_use_stratified_split(labels_mapped_all):
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels_mapped_all, test_size=0.2, random_state=42, stratify=labels_mapped_all
        )
    else:
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞)")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels_mapped_all, test_size=0.2, random_state=42, stratify=None
        )
    
    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_paths)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(val_paths)} –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
    train_transform, val_transform = get_transforms()
    
    train_dataset = TreeDataset(train_paths, train_labels, train_transform)
    val_dataset = TreeDataset(val_paths, val_labels, val_transform)
    
    batch_size = min(BATCH_SIZE, len(train_paths))
    if batch_size == 0:
        batch_size = 1
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    
    num_classes = len(unique_labels_sorted)
    model = create_simple_model(num_classes)
    
    # –û–±—É—á–µ–Ω–∏–µ
    model, history = train_model_safe(model, train_loader, val_loader, 
                                    min(NUM_EPOCHS, 5), num_classes, "–ø–æ—Ä–æ–¥—ã")

    return model, history, class_names, image_paths, labels_mapped_all

def train_defects_model_simple(characteristiki_folder_path):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫/–¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    
    print("üîç –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö")
    print("=" * 50)
    
    image_paths, labels, defect_descriptions = load_defects_data(characteristiki_folder_path)
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return None, None, [], [], []
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(labels))} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0..C-1
    unique_labels_sorted = sorted(set(labels))
    original_to_compact = {orig: idx for idx, orig in enumerate(unique_labels_sorted)}
    labels_mapped_all = [original_to_compact[l] for l in labels]

    # –°–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–ª–∞—Å—Å–æ–≤
    class_names = []
    for orig_label in unique_labels_sorted:
        for path_i, lab in enumerate(labels):
            if lab == orig_label:
                class_names.append(defect_descriptions[path_i])
                break

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if len(image_paths) <= 3:
        print("‚ö†Ô∏è –û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö! –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        train_paths, train_labels = image_paths, labels_mapped_all
        val_paths, val_labels = image_paths, labels_mapped_all
    elif can_use_stratified_split(labels_mapped_all):
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels_mapped_all, test_size=0.2, random_state=42, stratify=labels_mapped_all
        )
    else:
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞)")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            image_paths, labels_mapped_all, test_size=0.2, random_state=42, stratify=None
        )
    
    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_paths)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(val_paths)} –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
    train_transform, val_transform = get_transforms()
    
    train_dataset = TreeDataset(train_paths, train_labels, train_transform)
    val_dataset = TreeDataset(val_paths, val_labels, val_transform)
    
    batch_size = min(BATCH_SIZE, len(train_paths))
    if batch_size == 0:
        batch_size = 1
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)
    
    num_classes = len(unique_labels_sorted)
    model = create_simple_model(num_classes)
    
    # –û–±—É—á–µ–Ω–∏–µ
    model, history = train_model_safe(model, train_loader, val_loader, 
                                    min(NUM_EPOCHS, 5), num_classes, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")

    return model, history, class_names, image_paths, labels_mapped_all

def simple_test_model(model, test_image_path, class_names, model_type="–ø–æ—Ä–æ–¥—ã"):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    try:
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        transform = transforms.Compose([
            transforms.Resize(IMG_SIZE),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV –∫–∞–∫ fallback
        try:
            image = Image.open(test_image_path).convert('RGB')
        except:
            image_cv = cv2.imread(test_image_path)
            if image_cv is not None:
                image_cv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)
                image = Image.fromarray(image_cv)
            else:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image_path}")
                return None, 0
        
        image_tensor = transform(image).unsqueeze(0).to(DEVICE)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        model.eval()
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            confidence, predicted_class = torch.max(probabilities, 0)
        
        predicted_class = predicted_class.item()
        confidence = confidence.item()
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
        if predicted_class < len(class_names):
            class_name = class_names[predicted_class]
        else:
            class_name = f"–ö–ª–∞—Å—Å {predicted_class}"
        
        print(f"\nüîç –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø ({model_type}):")
        print(f"üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {Path(test_image_path).name}")
        print(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_name}")
        print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")
        
        return class_name, confidence
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ {test_image_path}: {e}")
        return None, 0

def evaluate_model_on_all_images(model, image_paths, true_labels, class_names, model_type="–ø–æ—Ä–æ–¥—ã"):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"""
    print(f"\nüìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –ù–ê –í–°–ï–• –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–• ({model_type}):")
    print("=" * 60)
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏")
        return 0
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    model.eval()
    correct_predictions = 0
    total_images = 0
    
    print(f"üî¢ –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {len(image_paths)}")
    print("-" * 60)
    
    for i, (img_path, true_label) in enumerate(zip(image_paths, true_labels)):
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å fallback
            try:
                image = Image.open(img_path).convert('RGB')
            except:
                image_cv = cv2.imread(img_path)
                if image_cv is not None:
                    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)
                    image = Image.fromarray(image_cv)
                else:
                    continue
            
            image_tensor = transform(image).unsqueeze(0).to(DEVICE)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = model(image_tensor)
                _, predicted_class = torch.max(outputs.data, 1)
            
            predicted_class = predicted_class.item()
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            is_correct = (predicted_class == true_label)
            if is_correct:
                correct_predictions += 1
            
            total_images += 1
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
            true_class_name = class_names[true_label] if true_label < len(class_names) else f"Class {true_label}"
            pred_class_name = class_names[predicted_class] if predicted_class < len(class_names) else f"Class {predicted_class}"
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —ç–º–æ–¥–∑–∏
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"{status} {i+1:2d}/{len(image_paths)}: {Path(img_path).name:15} | "
                  f"–ò—Å—Ç–∏–Ω–∞: {true_class_name:15} | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {pred_class_name:15}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ {img_path}: {e}")
            continue
    
    accuracy = correct_predictions / total_images if total_images > 0 else 0
    print("-" * 60)
    print(f"üéØ –ò–¢–û–ì–û–í–ê–Ø –¢–û–ß–ù–û–°–¢–¨: {accuracy:.2%} ({correct_predictions}/{total_images})")
    
    return accuracy

# –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´
if __name__ == "__main__":
    print("üå≤ –ó–ê–ü–£–°–ö –£–ü–†–û–©–ï–ù–ù–û–ô –°–ò–°–¢–ï–ú–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –î–ï–†–ï–í–¨–ï–í (PyTorch)")
    print("=" * 60)
    
    porody_path = "data/–ø–æ—Ä–æ–¥—ã"
    char_path = "data/—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"
    
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫
        if not Path(porody_path).exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ —Å –ø–æ—Ä–æ–¥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {porody_path}")
            porody_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø–æ—Ä–æ–¥–∞–º–∏: ")
        
        if not Path(char_path).exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {char_path}")
            char_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏: ")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Ä–æ–¥
        porody_model, porody_history, species_names, porody_images, porody_labels = train_tree_species_model_simple(porody_path)
        
        print("\n" + "=" * 60)
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã)
        defects_model, defects_history, defect_descriptions, defects_images, defects_labels = train_defects_model_simple(char_path)
        
        print("\n" + "=" * 60)
        print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        print("=" * 60)
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ—Ä–æ–¥
        if porody_model is not None and len(species_names) > 0 and len(porody_images) > 0:
            print("üå≥ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –ü–û–†–û–î:")
            test_image = porody_images[0]
            simple_test_model(porody_model, test_image, species_names, "–ø–æ—Ä–æ–¥—ã")
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            porody_accuracy = evaluate_model_on_all_images(
                porody_model, porody_images, porody_labels, species_names, "–ø–æ—Ä–æ–¥—ã"
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            try:
                torch.save({
                    'model_state_dict': porody_model.state_dict(),
                    'class_names': species_names,
                    'accuracy': porody_accuracy
                }, 'model_porody_simple.pth')
                print("‚úÖ –ú–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'model_porody_simple.pth'")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥: {e}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        if defects_model is not None and len(defect_descriptions) > 0 and len(defects_images) > 0:
            print("\nüîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö:")
            test_image = defects_images[0]
            simple_test_model(defects_model, test_image, defect_descriptions, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            defects_accuracy = evaluate_model_on_all_images(
                defects_model, defects_images, defects_labels, defect_descriptions, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            try:
                torch.save({
                    'model_state_dict': defects_model.state_dict(),
                    'class_names': defect_descriptions,
                    'accuracy': defects_accuracy
                }, 'model_defects_simple.pth')
                print("‚úÖ –ú–æ–¥–µ–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'model_defects_simple.pth'")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {e}")
        else:
            print("\n‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏")
        
        print("\nüéâ –ü–†–û–ì–†–ê–ú–ú–ê –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!")
        
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É")
