import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
from torchvision import models
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import warnings
import os
from PIL import Image
import cv2
from collections import Counter

# –û—Ç–∫–ª—é—á–∞–µ–º warnings
warnings.filterwarnings('ignore')
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
IMG_SIZE = (224, 224)
BATCH_SIZE = 16
NUM_EPOCHS = 50
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}")

class TreeDataset(Dataset):
    """–ö–∞—Å—Ç–æ–º–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–µ—Ä–µ–≤—å–µ–≤ —Å –Ω–∞–¥–µ–∂–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏
        image = self.load_image_safe(img_path)
        
        if self.transform:
            image = self.transform(image)
        
        return image, label
    
    def load_image_safe(self, img_path):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ fallback'–∞–º–∏"""
        try:
            # –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenCV
            image = cv2.imread(str(img_path))
            if image is not None:
                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                image = Image.fromarray(image)
                return image
        except:
            pass
        
        try:
            # –°–ø–æ—Å–æ–± 2: –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –Ω–∞–ø—Ä—è–º—É—é
            image = Image.open(img_path).convert('RGB')
            return image
        except:
            pass
        
        # –°–ø–æ—Å–æ–± 3: –°–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ fallback
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {img_path}, —Å–æ–∑–¥–∞–µ–º —á–µ—Ä–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        return Image.new('RGB', IMG_SIZE, color='black')

def load_tree_species_data(porody_folder_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥ –¥–µ—Ä–µ–≤—å–µ–≤"""
    porody_path = Path(porody_folder_path)
    
    print(f"üîç –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {porody_path.absolute()}")
    
    if not porody_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {porody_path}")
        return [], [], []
    
    # –ò—â–µ–º CSV —Ñ–∞–π–ª
    csv_path = porody_path / "labels" / "labels.csv"
    if not csv_path.exists():
        csv_path = porody_path / "labels.csv"
        if not csv_path.exists():
            print("‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return [], [], []
    
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
        print(f"‚úÖ CSV –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return [], [], []
    
    # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    images_dir = porody_path / "images"
    if not images_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ 'images' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return [], [], []
    
    images = []
    labels = []
    species_names = []
    
    successful = 0
    for _, row in df.iterrows():
        try:
            filename = str(row['filename']).strip()
            img_path = images_dir / filename
            
            if img_path.exists():
                images.append(str(img_path))
                labels.append(int(row['species_label']))
                species_names.append(str(row['species_name']))
                successful += 1
            else:
                print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {successful}/{len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(set(labels))}")
    
    return images, labels, species_names

def load_defects_data(characteristiki_folder_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫/–¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    char_path = Path(characteristiki_folder_path)
    
    print(f"üîç –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {char_path.absolute()}")
    
    if not char_path.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {char_path}")
        return [], [], []
    
    # –ò—â–µ–º CSV —Ñ–∞–π–ª
    csv_path = char_path / "labels" / "labels.csv"
    if not csv_path.exists():
        csv_path = char_path / "labels.csv"
        if not csv_path.exists():
            print("‚ùå CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return [], [], []
    
    try:
        try:
            df = pd.read_csv(csv_path, encoding='utf-8')
        except:
            df = pd.read_csv(csv_path, encoding='utf-8', on_bad_lines='skip')
        print(f"‚úÖ CSV –∑–∞–≥—Ä—É–∂–µ–Ω: {len(df)} –∑–∞–ø–∏—Å–µ–π")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV: {e}")
        return [], [], []
    
    # –ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
    images_dir = char_path / "images"
    if not images_dir.exists():
        print("‚ùå –ü–∞–ø–∫–∞ 'images' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return [], [], []
    
    images = []
    labels = []
    defect_descriptions = []
    
    successful = 0
    for _, row in df.iterrows():
        try:
            filename = str(row['filename']).strip()
            img_path = images_dir / filename
            
            if img_path.exists():
                images.append(str(img_path))
                labels.append(int(row['defect_label']))
                defect_descriptions.append(str(row['defect_description']))
                successful += 1
            else:
                print(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ: {filename}")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏: {e}")
            continue
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {successful}/{len(df)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print(f"üéØ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {len(set(labels))}")
    
    return images, labels, defect_descriptions

def get_enhanced_transforms():
    """–£–ª—É—á—à–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –±–æ–ª—å—à–µ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π"""
    train_transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.RandomHorizontalFlip(p=0.5),
        transforms.RandomVerticalFlip(p=0.2),
        transforms.RandomRotation(degrees=30),
        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),
        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),
        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    val_transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    return train_transform, val_transform

def create_improved_model(num_classes):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å batch normalization –∏ –±–æ–ª—å—à–µ–π –µ–º–∫–æ—Å—Ç—å—é"""
    class ImprovedCNN(nn.Module):
        def __init__(self, num_classes):
            super(ImprovedCNN, self).__init__()
            self.features = nn.Sequential(
                nn.Conv2d(3, 64, kernel_size=3, padding=1),
                nn.BatchNorm2d(64),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(64, 128, kernel_size=3, padding=1),
                nn.BatchNorm2d(128),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(128, 256, kernel_size=3, padding=1),
                nn.BatchNorm2d(256),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
                
                nn.Conv2d(256, 512, kernel_size=3, padding=1),
                nn.BatchNorm2d(512),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool2d((1, 1))
            )
            self.classifier = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(512, 256),
                nn.ReLU(inplace=True),
                nn.BatchNorm1d(256),
                nn.Dropout(0.3),
                nn.Linear(256, 128),
                nn.ReLU(inplace=True),
                nn.Linear(128, num_classes)
            )
        
        def forward(self, x):
            x = self.features(x)
            x = x.view(x.size(0), -1)
            x = self.classifier(x)
            return x
    
    return ImprovedCNN(num_classes)

def get_class_weights(labels, num_classes):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    class_counts = Counter(labels)
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {dict(class_counts)}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —á–∞—Å—Ç–æ—Ç–µ –∫–ª–∞—Å—Å–æ–≤
    weights = []
    for i in range(num_classes):
        if i in class_counts:
            weights.append(1.0 / class_counts[i])
        else:
            weights.append(1.0)  # –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∞ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–µ—Å–∞
    weights = np.array(weights)
    weights = weights / weights.sum() * len(weights)
    weights = torch.FloatTensor(weights).to(DEVICE)
    
    print(f"‚öñÔ∏è –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {weights.cpu().numpy()}")
    return weights

def check_class_balance(labels, class_names, dataset_name):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤"""
    label_counts = Counter(labels)
    
    print(f"\nüìä –ë–ê–õ–ê–ù–° –ö–õ–ê–°–°–û–í ({dataset_name}):")
    total_samples = len(labels)
    for label, count in label_counts.items():
        class_name = class_names[label] if label < len(class_names) else f"Class {label}"
        percentage = (count / total_samples) * 100
        print(f"  {class_name}: {count} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({percentage:.1f}%)")

def train_model_improved(model, train_loader, val_loader, num_epochs, num_classes, model_type="–ø–æ—Ä–æ–¥—ã"):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å scheduler –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"""
    model = model.to(DEVICE)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    train_labels = []
    for _, labels in train_loader:
        train_labels.extend(labels.cpu().numpy())
    
    class_weights = get_class_weights(train_labels, num_classes)
    criterion = nn.CrossEntropyLoss(weight=class_weights)
    
    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)
    
    train_losses = []
    val_accuracies = []
    learning_rates = []
    
    best_accuracy = 0
    best_model_state = None
    patience = 10
    patience_counter = 0
    
    print(f"üéØ –ù–ê–ß–ò–ù–ê–ï–ú –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò {model_type.upper()}...")
    print(f"üìà –í—Å–µ–≥–æ —ç–ø–æ—Ö: {num_epochs}, –†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(train_loader.dataset)}")
    
    for epoch in range(num_epochs):
        try:
            # –û–±—É—á–µ–Ω–∏–µ
            model.train()
            running_loss = 0.0
            batch_count = 0
            
            for batch_idx, (images, labels) in enumerate(train_loader):
                try:
                    images = images.to(DEVICE)
                    labels = labels.to(DEVICE)
                    
                    optimizer.zero_grad()
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    loss.backward()
                    
                    # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    optimizer.step()
                    
                    running_loss += loss.item()
                    batch_count += 1
                    
                    if batch_idx % 10 == 0:
                        current_lr = optimizer.param_groups[0]['lr']
                        print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}, LR: {current_lr:.2e}')
                        
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤ –±–∞—Ç—á–µ {batch_idx}: {e}")
                    continue
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            model.eval()
            correct = 0
            total = 0
            val_loss = 0.0
            
            with torch.no_grad():
                for images, labels in val_loader:
                    try:
                        images = images.to(DEVICE)
                        labels = labels.to(DEVICE)
                        outputs = model(images)
                        loss = criterion(outputs, labels)
                        val_loss += loss.item()
                        
                        _, predicted = torch.max(outputs.data, 1)
                        total += labels.size(0)
                        correct += (predicted == labels).sum().item()
                    except Exception as e:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                        continue
            
            accuracy = 100 * correct / total if total > 0 else 0
            avg_train_loss = running_loss / batch_count if batch_count > 0 else 0
            avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0
            
            current_lr = optimizer.param_groups[0]['lr']
            learning_rates.append(current_lr)
            train_losses.append(avg_train_loss)
            val_accuracies.append(accuracy)
            
            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%, LR: {current_lr:.2e}')
            
            # –û–±–Ω–æ–≤–ª—è–µ–º scheduler
            scheduler.step(accuracy)
            
            # Early stopping –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_model_state = model.state_dict().copy()
                patience_counter = 0
                print(f"üéâ –ù–æ–≤—ã–π —Ä–µ–∫–æ—Ä–¥ —Ç–æ—á–Ω–æ—Å—Ç–∏: {accuracy:.2f}%")
            else:
                patience_counter += 1
                
            if patience_counter >= patience:
                print(f"üõë Early stopping –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
                break
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —ç–ø–æ—Ö–µ {epoch+1}: {e}")
            continue
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º weights –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –≤–µ—Å–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é {best_accuracy:.2f}%")
    
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    return model, {'train_loss': train_losses, 'val_accuracy': val_accuracies, 'learning_rates': learning_rates}

def can_use_stratified_split(labels, test_size=0.2):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ"""
    label_counts = Counter(labels)
    min_samples_per_class = min(label_counts.values())
    
    # –î–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 –æ–±—Ä–∞–∑—Ü–∞ –≤ –∫–∞–∂–¥–æ–º –∫–ª–∞—Å—Å–µ
    return min_samples_per_class >= 2 and all(count >= int(1/test_size) + 1 for count in label_counts.values())

def apply_data_augmentation_balance(image_paths, labels, max_samples_per_class=100):
    """–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –º–∏–Ω–æ—Ä–∏—Ç–∞—Ä–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤"""
    label_counts = Counter(labels)
    max_count = max(label_counts.values())
    
    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if max_count <= min(label_counts.values()) * 2:
        return image_paths, labels
    
    print("üîÑ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é...")
    
    augmented_images = list(image_paths)
    augmented_labels = list(labels)
    
    for class_label, count in label_counts.items():
        if count < max_count:
            # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Å–∞
            class_indices = [i for i, label in enumerate(labels) if label == class_label]
            needed_samples = min(max_count - count, max_samples_per_class - count)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è)
            for i in range(needed_samples):
                original_idx = class_indices[i % len(class_indices)]
                augmented_images.append(image_paths[original_idx])
                augmented_labels.append(class_label)
    
    print(f"üìä –ü–æ—Å–ª–µ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏: {len(augmented_images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    return augmented_images, augmented_labels

def train_tree_species_model_improved(porody_folder_path):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Ä–æ–¥ –¥–µ—Ä–µ–≤—å–µ–≤"""
    
    print("üå≥ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –ü–û–†–û–î –î–ï–†–ï–í–¨–ï–í")
    print("=" * 50)
    
    image_paths, labels, species_names = load_tree_species_data(porody_folder_path)
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return None, None, [], [], []
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(labels))} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0..C-1
    unique_labels_sorted = sorted(set(labels))
    original_to_compact = {orig: idx for idx, orig in enumerate(unique_labels_sorted)}
    labels_mapped_all = [original_to_compact[l] for l in labels]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–ª–∞—Å—Å–æ–≤
    class_names = []
    for orig_label in unique_labels_sorted:
        for path_i, lab in enumerate(labels):
            if lab == orig_label:
                class_names.append(species_names[path_i])
                break

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
    check_class_balance(labels_mapped_all, class_names, "–ø–æ—Ä–æ–¥—ã (–∏—Å—Ö–æ–¥–Ω—ã–µ)")
    
    # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    balanced_paths, balanced_labels = apply_data_augmentation_balance(image_paths, labels_mapped_all)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if len(balanced_paths) <= 3:
        print("‚ö†Ô∏è –û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö! –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        train_paths, train_labels = balanced_paths, balanced_labels
        val_paths, val_labels = balanced_paths, balanced_labels
    elif can_use_stratified_split(balanced_labels):
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            balanced_paths, balanced_labels, test_size=0.2, random_state=42, stratify=balanced_labels
        )
    else:
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞)")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            balanced_paths, balanced_labels, test_size=0.2, random_state=42, stratify=None
        )
    
    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_paths)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(val_paths)} –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö")
    check_class_balance(train_labels, class_names, "–ø–æ—Ä–æ–¥—ã (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ)")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
    train_transform, val_transform = get_enhanced_transforms()
    
    train_dataset = TreeDataset(train_paths, train_labels, train_transform)
    val_dataset = TreeDataset(val_paths, val_labels, val_transform)
    
    batch_size = min(BATCH_SIZE, len(train_paths))
    if batch_size == 0:
        batch_size = 1
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
    
    num_classes = len(unique_labels_sorted)
    model = create_improved_model(num_classes)
    
    print(f"üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏: {num_classes} –∫–ª–∞—Å—Å–æ–≤")
    print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
    
    # –û–±—É—á–µ–Ω–∏–µ
    model, history = train_model_improved(model, train_loader, val_loader, 
                                        NUM_EPOCHS, num_classes, "–ø–æ—Ä–æ–¥—ã")

    return model, history, class_names, image_paths, labels_mapped_all

def train_defects_model_improved(characteristiki_folder_path):
    """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫/–¥–µ—Ñ–µ–∫—Ç–æ–≤"""
    
    print("üîç –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö")
    print("=" * 50)
    
    image_paths, labels, defect_descriptions = load_defects_data(characteristiki_folder_path)
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return None, None, [], [], []
    
    print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {len(image_paths)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, {len(set(labels))} –∫–ª–∞—Å—Å–æ–≤")
    
    # –ü—Ä–∏–≤–æ–¥–∏–º –º–µ—Ç–∫–∏ –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0..C-1
    unique_labels_sorted = sorted(set(labels))
    original_to_compact = {orig: idx for idx, orig in enumerate(unique_labels_sorted)}
    labels_mapped_all = [original_to_compact[l] for l in labels]

    # –°–ø–∏—Å–æ–∫ –∏–º—ë–Ω –∫–ª–∞—Å—Å–æ–≤
    class_names = []
    for orig_label in unique_labels_sorted:
        for path_i, lab in enumerate(labels):
            if lab == orig_label:
                class_names.append(defect_descriptions[path_i])
                break

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤
    check_class_balance(labels_mapped_all, class_names, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–∏—Å—Ö–æ–¥–Ω—ã–µ)")
    
    # –ë–∞–ª–∞–Ω—Å–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    balanced_paths, balanced_labels = apply_data_augmentation_balance(image_paths, labels_mapped_all)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    if len(balanced_paths) <= 3:
        print("‚ö†Ô∏è –û—á–µ–Ω—å –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö! –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        train_paths, train_labels = balanced_paths, balanced_labels
        val_paths, val_labels = balanced_paths, balanced_labels
    elif can_use_stratified_split(balanced_labels):
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            balanced_paths, balanced_labels, test_size=0.2, random_state=42, stratify=balanced_labels
        )
    else:
        print("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞)")
        train_paths, val_paths, train_labels, val_labels = train_test_split(
            balanced_paths, balanced_labels, test_size=0.2, random_state=42, stratify=None
        )
    
    print(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ: {len(train_paths)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö, {len(val_paths)} –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö")
    check_class_balance(train_labels, class_names, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ)")
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã
    train_transform, val_transform = get_enhanced_transforms()
    
    train_dataset = TreeDataset(train_paths, train_labels, train_transform)
    val_dataset = TreeDataset(val_paths, val_labels, val_transform)
    
    batch_size = min(BATCH_SIZE, len(train_paths))
    if batch_size == 0:
        batch_size = 1
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
    
    num_classes = len(unique_labels_sorted)
    model = create_improved_model(num_classes)
    
    print(f"üß† –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏: {num_classes} –∫–ª–∞—Å—Å–æ–≤")
    print(f"üì¶ –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {batch_size}")
    
    # –û–±—É—á–µ–Ω–∏–µ
    model, history = train_model_improved(model, train_loader, val_loader, 
                                        NUM_EPOCHS, num_classes, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")

    return model, history, class_names, image_paths, labels_mapped_all

def simple_test_model(model, test_image_path, class_names, model_type="–ø–æ—Ä–æ–¥—ã"):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    try:
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        transform = transforms.Compose([
            transforms.Resize(IMG_SIZE),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV –∫–∞–∫ fallback
        try:
            image = Image.open(test_image_path).convert('RGB')
        except:
            image_cv = cv2.imread(test_image_path)
            if image_cv is not None:
                image_cv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)
                image = Image.fromarray(image_cv)
            else:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image_path}")
                return None, 0
        
        image_tensor = transform(image).unsqueeze(0).to(DEVICE)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        model.eval()
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            confidence, predicted_class = torch.max(probabilities, 0)
        
        predicted_class = predicted_class.item()
        confidence = confidence.item()
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞
        if predicted_class < len(class_names):
            class_name = class_names[predicted_class]
        else:
            class_name = f"–ö–ª–∞—Å—Å {predicted_class}"
        
        print(f"\nüîç –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø ({model_type}):")
        print(f"üì∏ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {Path(test_image_path).name}")
        print(f"üéØ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {class_name}")
        print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2%}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        top3_probs, top3_classes = torch.topk(probabilities, 3)
        print("üèÜ –¢–æ–ø-3 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
        for i in range(3):
            class_idx = top3_classes[i].item()
            prob = top3_probs[i].item()
            class_name = class_names[class_idx] if class_idx < len(class_names) else f"Class {class_idx}"
            print(f"  {i+1}. {class_name}: {prob:.2%}")
        
        return class_name, confidence
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ {test_image_path}: {e}")
        return None, 0

def evaluate_model_on_all_images(model, image_paths, true_labels, class_names, model_type="–ø–æ—Ä–æ–¥—ã"):
    """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"""
    print(f"\nüìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò –ù–ê –í–°–ï–• –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–• ({model_type}):")
    print("=" * 60)
    
    if len(image_paths) == 0:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ü–µ–Ω–∫–∏")
        return 0
    
    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    transform = transforms.Compose([
        transforms.Resize(IMG_SIZE),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    model.eval()
    correct_predictions = 0
    total_images = 0
    
    # –ú–∞—Ç—Ä–∏—Ü–∞Ê∑∑Ê∑Ü–º–æ—Å—Ç–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
    confusion_dict = {}
    
    print(f"üî¢ –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ—Ü–µ–Ω–∫–∏: {len(image_paths)}")
    print("-" * 60)
    
    for i, (img_path, true_label) in enumerate(zip(image_paths, true_labels)):
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å fallback
            try:
                image = Image.open(img_path).convert('RGB')
            except:
                image_cv = cv2.imread(img_path)
                if image_cv is not None:
                    image_cv = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)
                    image = Image.fromarray(image_cv)
                else:
                    continue
            
            image_tensor = transform(image).unsqueeze(0).to(DEVICE)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            with torch.no_grad():
                outputs = model(image_tensor)
                _, predicted_class = torch.max(outputs.data, 1)
            
            predicted_class = predicted_class.item()
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –º–∞—Ç—Ä–∏—Ü—ÉÊ∑∑Ê∑Ü–º–æ—Å—Ç–∏
            if true_label not in confusion_dict:
                confusion_dict[true_label] = {}
            if predicted_class not in confusion_dict[true_label]:
                confusion_dict[true_label][predicted_class] = 0
            confusion_dict[true_label][predicted_class] += 1
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            is_correct = (predicted_class == true_label)
            if is_correct:
                correct_predictions += 1
            
            total_images += 1
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
            true_class_name = class_names[true_label] if true_label < len(class_names) else f"Class {true_label}"
            pred_class_name = class_names[predicted_class] if predicted_class < len(class_names) else f"Class {predicted_class}"
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —ç–º–æ–¥–∑–∏
            status = "‚úÖ" if is_correct else "‚ùå"
            print(f"{status} {i+1:3d}/{len(image_paths)}: {Path(img_path).name:20} | "
                  f"–ò—Å—Ç–∏–Ω–∞: {true_class_name:25} | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {pred_class_name:25}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ {img_path}: {e}")
            continue
    
    accuracy = correct_predictions / total_images if total_images > 0 else 0
    print("-" * 60)
    print(f"üéØ –ò–¢–û–ì–û–í–ê–Ø –¢–û–ß–ù–û–°–¢–¨: {accuracy:.2%} ({correct_predictions}/{total_images})")
    
    # –í—ã–≤–æ–¥–∏–º –º–∞—Ç—Ä–∏—Ü—ÉÊ∑∑Ê∑Ü–º–æ—Å—Ç–∏
    print("\nüìã –ú–ê–¢–†–ò–¶–ê –û–®–ò–ë–û–ö (–æ—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏):")
    for true_label in sorted(confusion_dict.keys()):
        true_class_name = class_names[true_label] if true_label < len(class_names) else f"Class {true_label}"
        predictions = confusion_dict[true_label]
        
        correct_count = predictions.get(true_label, 0)
        total_count = sum(predictions.values())
        accuracy_class = correct_count / total_count if total_count > 0 else 0
        
        print(f"\n{true_class_name} (—Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy_class:.1%}):")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏
        for pred_label, count in sorted(predictions.items(), key=lambda x: x[1], reverse=True):
            if pred_label != true_label and count > 0:
                pred_class_name = class_names[pred_label] if pred_label < len(class_names) else f"Class {pred_label}"
                print(f"  ‚Üí –æ—à–∏–±–æ—á–Ω–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω –∫–∞–∫ '{pred_class_name}': {count} —Ä–∞–∑")
    
    return accuracy

def plot_training_history(history, model_type):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
        ax1.plot(history['train_loss'], label='Training Loss')
        ax1.set_title(f'{model_type} - Training Loss')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
        ax2.plot(history['val_accuracy'], label='Validation Accuracy', color='orange')
        ax2.set_title(f'{model_type} - Validation Accuracy')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy (%)')
        ax2.legend()
        ax2.grid(True)
        
        plt.tight_layout()
        plt.savefig(f'training_history_{model_type}.png', dpi=300, bbox_inches='tight')
        plt.show()
        
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏: {e}")

# –ó–ê–ü–£–°–ö –ü–†–û–ì–†–ê–ú–ú–´
if __name__ == "__main__":
    print("üå≤ –ó–ê–ü–£–°–ö –£–õ–£–ß–®–ï–ù–ù–û–ô –°–ò–°–¢–ï–ú–´ –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –î–ï–†–ï–í–¨–ï–í (PyTorch)")
    print("=" * 60)
    
    porody_path = "data/–ø–æ—Ä–æ–¥—ã"
    char_path = "data/—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"
    
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫
        if not Path(porody_path).exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ —Å –ø–æ—Ä–æ–¥–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {porody_path}")
            porody_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –ø–æ—Ä–æ–¥–∞–º–∏: ")
        
        if not Path(char_path).exists():
            print(f"‚ùå –ü–∞–ø–∫–∞ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {char_path}")
            char_path = input("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏: ")
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Ä–æ–¥
        porody_model, porody_history, species_names, porody_images, porody_labels = train_tree_species_model_improved(porody_path)
        
        print("\n" + "=" * 60)
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã)
        defects_model, defects_history, defect_descriptions, defects_images, defects_labels = train_defects_model_improved(char_path)
        
        print("\n" + "=" * 60)
        print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
        print("=" * 60)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
        if porody_history:
            plot_training_history(porody_history, "–ø–æ—Ä–æ–¥—ã")
        if defects_history:
            plot_training_history(defects_history, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ—Ä–æ–¥
        if porody_model is not None and len(species_names) > 0 and len(porody_images) > 0:
            print("üå≥ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –ü–û–†–û–î:")
            test_image = porody_images[0]
            simple_test_model(porody_model, test_image, species_names, "–ø–æ—Ä–æ–¥—ã")
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            porody_accuracy = evaluate_model_on_all_images(
                porody_model, porody_images, porody_labels, species_names, "–ø–æ—Ä–æ–¥—ã"
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            try:
                torch.save({
                    'model_state_dict': porody_model.state_dict(),
                    'class_names': species_names,
                    'accuracy': porody_accuracy,
                    'history': porody_history
                }, 'model_porody_improved.pth')
                print("‚úÖ –ú–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'model_porody_improved.pth'")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –ø–æ—Ä–æ–¥: {e}")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        if defects_model is not None and len(defect_descriptions) > 0 and len(defects_images) > 0:
            print("\nüîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö:")
            test_image = defects_images[0]
            simple_test_model(defects_model, test_image, defect_descriptions, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏")
            
            # –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö
            defects_accuracy = evaluate_model_on_all_images(
                defects_model, defects_images, defects_labels, defect_descriptions, "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏"
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            try:
                torch.save({
                    'model_state_dict': defects_model.state_dict(),
                    'class_names': defect_descriptions,
                    'accuracy': defects_accuracy,
                    'history': defects_history
                }, 'model_defects_improved.pth')
                print("‚úÖ –ú–æ–¥–µ–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ 'model_defects_improved.pth'")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {e}")
        else:
            print("\n‚ö†Ô∏è –ú–æ–¥–µ–ª—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å –¥–∞–Ω–Ω—ã–º–∏")
        
        print("\nüéâ –ü–†–û–ì–†–ê–ú–ú–ê –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!")
        
    except Exception as e:
        print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º—É")


